{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4 - Autoencoder\n",
    "\n",
    "Ein Autoencoder ist ein neuronales Netz, das darauf trainiert werden\n",
    "soll, als Ausgabe die Eingabedaten zu reproduzieren. Es gibt\n",
    "einen Hidden Layer h, der als Code bezeichnet wird und die Eingabedaten\n",
    "repräsentiert. Der Code enthält alle nötigen Informationen,\n",
    "um das Eingangsbild wiederherzustellen. An dieser Stelle wird die\n",
    "Struktur des Autoencoders meist in zwei Komponenten geteilt, dem\n",
    "Encoder und dem Decoder. Der Encoder erzeugt den Code\n",
    "und der Decoder rekonstruiert die Eingangsdaten anhand der Repräsentation durch die Code-Schicht. \n",
    "Folglich muss der Decoder alle Schritte des Encoders rückgängig machen, um auf die Eingangsdaten zu kommen. \n",
    "\n",
    "![alt text](autoencoder.png)\n",
    "\n",
    "\n",
    "### Hinweise\n",
    "* Überlege dir eine geeignete Darstellung des Codes (beispielsweise ein Feature Vektor mit 5 Merkmalen, aus denen dann wieder ein Gesicht rekonstruiert werden soll. \n",
    "* Du wirst den Layer \"Reshape\" brauchen: https://keras.io/layers/core/#reshape\n",
    "* Die Inverse von Conv2D ist Conv2DTranspose: https://keras.io/layers/convolutional/#conv2dtranspose\n",
    "* Beispiel Autoencoder: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* Idee: Nutze den Parameter 'strides=2' bei Convolution und Transpose Convolution\n",
    "* Tipp: Bei zu vielen Schichten verbringst du den restlichen Workshop mit Warten :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importiere Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, InputLayer, Conv2DTranspose\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, MaxPool2D\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lade Bilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lade n Gesichter. In der SEU sind insgesamt 1000 Bilder gespeichert\n",
    "n = 1\n",
    "X,Y = utils.LoadFaces(n)\n",
    "print(X.shape)\n",
    "width = X.shape[2]\n",
    "height = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition der Anzahl der Neuronen in der kleinsten Zwischenschicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Die Anzahl der Neuronen in der kleinsten Zwischenschicht\n",
    "nLatentSpace = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Definiere das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baue den Encoder des Netzwerkes\n",
    "encoder = Sequential()\n",
    "encoder.add(InputLayer(input_shape=(...)))\n",
    "encoder.add(...)\n",
    "...\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baue den Decoder des Netzwerkes\n",
    "decoder = Sequential()\n",
    "decoder.add(InputLayer(input_shape=(...)))\n",
    "decoder.add(...)\n",
    "...\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baue beides zusammen -> Autoencoder\n",
    "model = Sequential()\n",
    "model.add(encoder)\n",
    "model.add(decoder)\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Konfiguriere den Lernalgorithmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer & Loss\n",
    "optimizer = ...\n",
    "loss = ...\n",
    "# Model kompilieren \n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Lass dein Modell lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Du kannst batch_size, Anzahl der Epochen und den validation_split anpassen \n",
    "# Denk daran, den Parameter callbacks=[TQDMNotebookCallback()] zu übergeben und verbose=0 zu setzen\n",
    "history = model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testphase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ändere den Index, um weitere Bilder anzuschauen\n",
    "idx = 0\n",
    "output = model.predict(X[idx:idx+1])[0]\n",
    "utils.ShowImage(np.concatenate((X[idx], output), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plote die KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel Featurevektor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Featurevektor extrahieren\n",
    "idx = 1\n",
    "encoder.predict(X[idx:idx+1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Generiere zufällige Gesichter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Erzeuge ein zufälliges Gesicht\n",
    "random = np.random.rand(1, nLatentSpace) * 20 - 10\n",
    "utils.ShowImage(decoder.predict(random)[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
