{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1: Einführung mit OR, AND und XOR\n",
    "Wir haben Dir hier eine Lösung für ein neuronales Netz gegeben, das die logische Funktion OR lernt. Erweitere das Netz so, dass es nun ein AND und wenn das geklappt hat, dann noch das XOR lernt. \n",
    "\n",
    "### Hinweise\n",
    "* Sequential, `fit`, `compile`: https://keras.io/models/sequential/\n",
    "* Dense Layer ( = Fully Connected Layer): https://keras.io/layers/core/#dense\n",
    "* Loss functions: https://keras.io/losses/ \n",
    "* Optimizers: https://keras.io/optimizers/\n",
    "* Activation functions: https://keras.io/activations/\n",
    "* Spätestens für das XOR wirst du mehr als einen Layer benötigen. \n",
    "\n",
    "### Nützliches \n",
    "* Übersicht und Erklärung zu Loss Functions: https://isaacchanghau.github.io/post/loss_functions/\n",
    "* Übersicht und Erklärung zu Optimizers: http://ruder.io/optimizing-gradient-descent/ \n",
    "* Paar Infos über Activation Functions: https://towardsdatascience.com/activation-functions-and-its-types-which-is-better-a9a5310cc8f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importiere Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Library, die eine einfache Handhabung \n",
    "# von Vektoren, Matrizen oder generell \n",
    "# großen mehrdimensionalen Arrays ermöglicht.\n",
    "import numpy as np\n",
    "\n",
    "# Keras spezifische Importe\n",
    "from keras.models import Sequential, InputLayer\n",
    "from keras.layers.core import Dense\n",
    "from keras import losses, optimizers\n",
    "\n",
    "# Library für die Ausgabe von Grafiken\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Definiere Eingabe und die erwartete Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unsere Trainingsdaten\n",
    "# X = input\n",
    "# Y = output\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([ [0],  [1],  [1],  [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Definiere das Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Definition des Neuronalen Netzes\n",
    "# Sequential bedeutet, dass wir mehrere Layer (sequentiell) hintereinander schachteln\n",
    "model = Sequential()\n",
    "# Definition der Dimension der Inputdaten. In unserem Fall 2 \n",
    "model.add(InputLayer(input_shape=(2,)))\n",
    "# Ein Fully Connected Layer mit sigmoiden Aktivierungsfunction\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zusammenfassung. Du kannst die Anzahl der trainierbaren Parameter sehen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Die initialen Gewichte sind zufällig\n",
    "print(model.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Konfiguriere den Lernalgorithmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Optimierung mittels Gradientenabstieg (Lernrate lr=0.3)\n",
    "adam = optimizers.Adam(lr=0.3)\n",
    "# Kostenfunktion über mittlere quadratische Abweichung\n",
    "mse = losses.mean_squared_error\n",
    "# Model wird jetzt kompiliert. Dazu geben wir die Funktion an, über die das Model optimiert werden soll sowie den Optimizer \n",
    "# In diesem Fall ist es der quadratische Abstand zwischen gewünschter Ausgabe Y und gelernter Ausgabe \n",
    "model.compile(loss=mse, optimizer=adam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO:</span> Lass dein Modell lernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Trainingsphase\n",
    "history = model.fit(X, Y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testphase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Die Ausgaben des Models für alle 4 Eingaben\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Die Gewichte haben sich geändert\n",
    "print(model.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ausgabe der \"Geschichte\" des Lernprozesses\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
